// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Yandex.Inputs
{

    public sealed class MdbClickhouseClusterUserSettingsGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// Include CORS headers in HTTP responces.
        /// </summary>
        [Input("addHttpCorsHeader")]
        public Input<bool>? AddHttpCorsHeader { get; set; }

        /// <summary>
        /// Allows or denies DDL queries.
        /// </summary>
        [Input("allowDdl")]
        public Input<bool>? AllowDdl { get; set; }

        /// <summary>
        /// Enable compilation of queries.
        /// </summary>
        [Input("compile")]
        public Input<bool>? Compile { get; set; }

        /// <summary>
        /// Turn on expression compilation.
        /// </summary>
        [Input("compileExpressions")]
        public Input<bool>? CompileExpressions { get; set; }

        /// <summary>
        /// Connect timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("connectTimeout")]
        public Input<int>? ConnectTimeout { get; set; }

        /// <summary>
        /// Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
        /// </summary>
        [Input("countDistinctImplementation")]
        public Input<string>? CountDistinctImplementation { get; set; }

        /// <summary>
        /// Sets behaviour on overflow when using DISTINCT. Possible values:
        /// </summary>
        [Input("distinctOverflowMode")]
        public Input<string>? DistinctOverflowMode { get; set; }

        /// <summary>
        /// Determine the behavior of distributed subqueries.
        /// </summary>
        [Input("distributedAggregationMemoryEfficient")]
        public Input<bool>? DistributedAggregationMemoryEfficient { get; set; }

        /// <summary>
        /// Timeout for DDL queries, in milliseconds.
        /// </summary>
        [Input("distributedDdlTaskTimeout")]
        public Input<int>? DistributedDdlTaskTimeout { get; set; }

        /// <summary>
        /// Changes the behaviour of distributed subqueries.
        /// </summary>
        [Input("distributedProductMode")]
        public Input<string>? DistributedProductMode { get; set; }

        /// <summary>
        /// Allows to retunr empty result.
        /// </summary>
        [Input("emptyResultForAggregationByEmptySet")]
        public Input<bool>? EmptyResultForAggregationByEmptySet { get; set; }

        /// <summary>
        /// Enables or disables data compression in the response to an HTTP request.
        /// </summary>
        [Input("enableHttpCompression")]
        public Input<bool>? EnableHttpCompression { get; set; }

        /// <summary>
        /// Forces a query to an out-of-date replica if updated data is not available.
        /// </summary>
        [Input("fallbackToStaleReplicasForDistributedQueries")]
        public Input<bool>? FallbackToStaleReplicasForDistributedQueries { get; set; }

        /// <summary>
        /// Disables query execution if the index can’t be used by date.
        /// </summary>
        [Input("forceIndexByDate")]
        public Input<bool>? ForceIndexByDate { get; set; }

        /// <summary>
        /// Disables query execution if indexing by the primary key is not possible.
        /// </summary>
        [Input("forcePrimaryKey")]
        public Input<bool>? ForcePrimaryKey { get; set; }

        /// <summary>
        /// Sets behaviour on overflow while GROUP BY operation. Possible values:
        /// </summary>
        [Input("groupByOverflowMode")]
        public Input<string>? GroupByOverflowMode { get; set; }

        /// <summary>
        /// Sets the threshold of the number of keys, after that the two-level aggregation should be used.
        /// </summary>
        [Input("groupByTwoLevelThreshold")]
        public Input<int>? GroupByTwoLevelThreshold { get; set; }

        /// <summary>
        /// Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
        /// </summary>
        [Input("groupByTwoLevelThresholdBytes")]
        public Input<int>? GroupByTwoLevelThresholdBytes { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpConnectionTimeout")]
        public Input<int>? HttpConnectionTimeout { get; set; }

        /// <summary>
        /// Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
        /// </summary>
        [Input("httpHeadersProgressInterval")]
        public Input<int>? HttpHeadersProgressInterval { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpReceiveTimeout")]
        public Input<int>? HttpReceiveTimeout { get; set; }

        /// <summary>
        /// Timeout for HTTP connection in milliseconds.
        /// </summary>
        [Input("httpSendTimeout")]
        public Input<int>? HttpSendTimeout { get; set; }

        /// <summary>
        /// When performing INSERT queries, replace omitted input column values with default values of the respective columns.
        /// </summary>
        [Input("inputFormatDefaultsForOmittedFields")]
        public Input<bool>? InputFormatDefaultsForOmittedFields { get; set; }

        /// <summary>
        /// Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
        /// </summary>
        [Input("inputFormatValuesInterpretExpressions")]
        public Input<bool>? InputFormatValuesInterpretExpressions { get; set; }

        /// <summary>
        /// Enables the quorum writes.
        /// </summary>
        [Input("insertQuorum")]
        public Input<int>? InsertQuorum { get; set; }

        /// <summary>
        /// Write to a quorum timeout in milliseconds.
        /// </summary>
        [Input("insertQuorumTimeout")]
        public Input<int>? InsertQuorumTimeout { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in JOIN. Possible values:
        /// </summary>
        [Input("joinOverflowMode")]
        public Input<string>? JoinOverflowMode { get; set; }

        /// <summary>
        /// Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
        /// </summary>
        [Input("joinUseNulls")]
        public Input<bool>? JoinUseNulls { get; set; }

        /// <summary>
        /// Require aliases for subselects and table functions in FROM that more than one table is present.
        /// </summary>
        [Input("joinedSubqueryRequiresAlias")]
        public Input<bool>? JoinedSubqueryRequiresAlias { get; set; }

        /// <summary>
        /// Allows or restricts using the LowCardinality data type with the Native format.
        /// </summary>
        [Input("lowCardinalityAllowInNativeFormat")]
        public Input<bool>? LowCardinalityAllowInNativeFormat { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree depth.
        /// </summary>
        [Input("maxAstDepth")]
        public Input<int>? MaxAstDepth { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree elements.
        /// </summary>
        [Input("maxAstElements")]
        public Input<int>? MaxAstElements { get; set; }

        /// <summary>
        /// A recommendation for what size of the block (in a count of rows) to load from tables.
        /// </summary>
        [Input("maxBlockSize")]
        public Input<int>? MaxBlockSize { get; set; }

        /// <summary>
        /// Limit in bytes for using memoru for GROUP BY before using swap on disk.
        /// </summary>
        [Input("maxBytesBeforeExternalGroupBy")]
        public Input<int>? MaxBytesBeforeExternalGroupBy { get; set; }

        /// <summary>
        /// This setting is equivalent of the max_bytes_before_external_group_by setting, except for it is for sort operation (ORDER BY), not aggregation.
        /// </summary>
        [Input("maxBytesBeforeExternalSort")]
        public Input<int>? MaxBytesBeforeExternalSort { get; set; }

        /// <summary>
        /// Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
        /// </summary>
        [Input("maxBytesInDistinct")]
        public Input<int>? MaxBytesInDistinct { get; set; }

        /// <summary>
        /// Limit on maximum size of the hash table for JOIN, in bytes.
        /// </summary>
        [Input("maxBytesInJoin")]
        public Input<int>? MaxBytesInJoin { get; set; }

        /// <summary>
        /// Limit on the number of bytes in the set resulting from the execution of the IN section.
        /// </summary>
        [Input("maxBytesInSet")]
        public Input<int>? MaxBytesInSet { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
        /// </summary>
        [Input("maxBytesToRead")]
        public Input<int>? MaxBytesToRead { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
        /// </summary>
        [Input("maxBytesToSort")]
        public Input<int>? MaxBytesToSort { get; set; }

        /// <summary>
        /// Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
        /// </summary>
        [Input("maxBytesToTransfer")]
        public Input<int>? MaxBytesToTransfer { get; set; }

        /// <summary>
        /// Limits the maximum number of columns that can be read from a table in a single query.
        /// </summary>
        [Input("maxColumnsToRead")]
        public Input<int>? MaxColumnsToRead { get; set; }

        /// <summary>
        /// Limits the maximum query execution time in milliseconds.
        /// </summary>
        [Input("maxExecutionTime")]
        public Input<int>? MaxExecutionTime { get; set; }

        /// <summary>
        /// Maximum abstract syntax tree depth after after expansion of aliases.
        /// </summary>
        [Input("maxExpandedAstElements")]
        public Input<int>? MaxExpandedAstElements { get; set; }

        /// <summary>
        /// The size of blocks (in a count of rows) to form for insertion into a table.
        /// </summary>
        [Input("maxInsertBlockSize")]
        public Input<int>? MaxInsertBlockSize { get; set; }

        /// <summary>
        /// Limits the maximum memory usage (in bytes) for processing queries on a single server.
        /// </summary>
        [Input("maxMemoryUsage")]
        public Input<int>? MaxMemoryUsage { get; set; }

        /// <summary>
        /// Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
        /// </summary>
        [Input("maxMemoryUsageForUser")]
        public Input<int>? MaxMemoryUsageForUser { get; set; }

        /// <summary>
        /// Limits the speed of the data exchange over the network in bytes per second.
        /// </summary>
        [Input("maxNetworkBandwidth")]
        public Input<int>? MaxNetworkBandwidth { get; set; }

        /// <summary>
        /// Limits the speed of the data exchange over the network in bytes per second.
        /// </summary>
        [Input("maxNetworkBandwidthForUser")]
        public Input<int>? MaxNetworkBandwidthForUser { get; set; }

        /// <summary>
        /// The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
        /// </summary>
        [Input("maxQuerySize")]
        public Input<int>? MaxQuerySize { get; set; }

        /// <summary>
        /// Disables lagging replicas for distributed queries.
        /// </summary>
        [Input("maxReplicaDelayForDistributedQueries")]
        public Input<int>? MaxReplicaDelayForDistributedQueries { get; set; }

        /// <summary>
        /// Limits the number of bytes in the result.
        /// </summary>
        [Input("maxResultBytes")]
        public Input<int>? MaxResultBytes { get; set; }

        /// <summary>
        /// Limits the number of rows in the result.
        /// </summary>
        [Input("maxResultRows")]
        public Input<int>? MaxResultRows { get; set; }

        /// <summary>
        /// Limits the maximum number of different rows when using DISTINCT.
        /// </summary>
        [Input("maxRowsInDistinct")]
        public Input<int>? MaxRowsInDistinct { get; set; }

        /// <summary>
        /// Limit on maximum size of the hash table for JOIN, in rows.
        /// </summary>
        [Input("maxRowsInJoin")]
        public Input<int>? MaxRowsInJoin { get; set; }

        /// <summary>
        /// Limit on the number of rows in the set resulting from the execution of the IN section.
        /// </summary>
        [Input("maxRowsInSet")]
        public Input<int>? MaxRowsInSet { get; set; }

        /// <summary>
        /// Limits the maximum number of unique keys received from aggregation function.
        /// </summary>
        [Input("maxRowsToGroupBy")]
        public Input<int>? MaxRowsToGroupBy { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be read from a table when running a query.
        /// </summary>
        [Input("maxRowsToRead")]
        public Input<int>? MaxRowsToRead { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be read from a table for sorting.
        /// </summary>
        [Input("maxRowsToSort")]
        public Input<int>? MaxRowsToSort { get; set; }

        /// <summary>
        /// Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
        /// </summary>
        [Input("maxRowsToTransfer")]
        public Input<int>? MaxRowsToTransfer { get; set; }

        /// <summary>
        /// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
        /// </summary>
        [Input("maxTemporaryColumns")]
        public Input<int>? MaxTemporaryColumns { get; set; }

        /// <summary>
        /// Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
        /// </summary>
        [Input("maxTemporaryNonConstColumns")]
        public Input<int>? MaxTemporaryNonConstColumns { get; set; }

        /// <summary>
        /// The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
        /// </summary>
        [Input("maxThreads")]
        public Input<int>? MaxThreads { get; set; }

        /// <summary>
        /// If ClickHouse should read more than merge_tree_max_bytes_to_use_cache bytes in one query, it doesn’t use the cache of uncompressed blocks.
        /// </summary>
        [Input("mergeTreeMaxBytesToUseCache")]
        public Input<int>? MergeTreeMaxBytesToUseCache { get; set; }

        /// <summary>
        /// If ClickHouse should read more than merge_tree_max_rows_to_use_cache rows in one query, it doesn’t use the cache of uncompressed blocks.
        /// </summary>
        [Input("mergeTreeMaxRowsToUseCache")]
        public Input<int>? MergeTreeMaxRowsToUseCache { get; set; }

        /// <summary>
        /// If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
        /// </summary>
        [Input("mergeTreeMinBytesForConcurrentRead")]
        public Input<int>? MergeTreeMinBytesForConcurrentRead { get; set; }

        /// <summary>
        /// If the number of rows to be read from a file of a MergeTree table exceeds merge_tree_min_rows_for_concurrent_read then ClickHouse tries to perform a concurrent reading from this file on several threads.
        /// </summary>
        [Input("mergeTreeMinRowsForConcurrentRead")]
        public Input<int>? MergeTreeMinRowsForConcurrentRead { get; set; }

        /// <summary>
        /// The minimum data volume required for using direct I/O access to the storage disk.
        /// </summary>
        [Input("minBytesToUseDirectIo")]
        public Input<int>? MinBytesToUseDirectIo { get; set; }

        /// <summary>
        /// How many times to potentially use a compiled chunk of code before running compilation.
        /// </summary>
        [Input("minCountToCompile")]
        public Input<int>? MinCountToCompile { get; set; }

        /// <summary>
        /// A query waits for expression compilation process to complete prior to continuing execution.
        /// </summary>
        [Input("minCountToCompileExpression")]
        public Input<int>? MinCountToCompileExpression { get; set; }

        /// <summary>
        /// Minimal execution speed in rows per second.
        /// </summary>
        [Input("minExecutionSpeed")]
        public Input<int>? MinExecutionSpeed { get; set; }

        /// <summary>
        /// Minimal execution speed in bytes per second.
        /// </summary>
        [Input("minExecutionSpeedBytes")]
        public Input<int>? MinExecutionSpeedBytes { get; set; }

        /// <summary>
        /// Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
        /// </summary>
        [Input("minInsertBlockSizeBytes")]
        public Input<int>? MinInsertBlockSizeBytes { get; set; }

        /// <summary>
        /// Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
        /// </summary>
        [Input("minInsertBlockSizeRows")]
        public Input<int>? MinInsertBlockSizeRows { get; set; }

        /// <summary>
        /// If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
        /// </summary>
        [Input("outputFormatJsonQuote64bitIntegers")]
        public Input<bool>? OutputFormatJsonQuote64bitIntegers { get; set; }

        /// <summary>
        /// Enables +nan, -nan, +inf, -inf outputs in JSON output format.
        /// </summary>
        [Input("outputFormatJsonQuoteDenormals")]
        public Input<bool>? OutputFormatJsonQuoteDenormals { get; set; }

        /// <summary>
        /// Query priority.
        /// </summary>
        [Input("priority")]
        public Input<int>? Priority { get; set; }

        /// <summary>
        /// Quota accounting mode.
        /// </summary>
        [Input("quotaMode")]
        public Input<string>? QuotaMode { get; set; }

        /// <summary>
        /// Sets behaviour on overflow while read. Possible values:
        /// </summary>
        [Input("readOverflowMode")]
        public Input<string>? ReadOverflowMode { get; set; }

        /// <summary>
        /// Restricts permissions for reading data, write data and change settings queries.
        /// </summary>
        [Input("readonly")]
        public Input<int>? Readonly { get; set; }

        /// <summary>
        /// Receive timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("receiveTimeout")]
        public Input<int>? ReceiveTimeout { get; set; }

        /// <summary>
        /// For ALTER ... ATTACH|DETACH|DROP queries, you can use the replication_alter_partitions_sync setting to set up waiting.
        /// </summary>
        [Input("replicationAlterPartitionsSync")]
        public Input<int>? ReplicationAlterPartitionsSync { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in result. Possible values:
        /// </summary>
        [Input("resultOverflowMode")]
        public Input<string>? ResultOverflowMode { get; set; }

        /// <summary>
        /// Enables or disables sequential consistency for SELECT queries.
        /// </summary>
        [Input("selectSequentialConsistency")]
        public Input<bool>? SelectSequentialConsistency { get; set; }

        /// <summary>
        /// Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
        /// </summary>
        [Input("sendProgressInHttpHeaders")]
        public Input<bool>? SendProgressInHttpHeaders { get; set; }

        /// <summary>
        /// Send timeout in milliseconds on the socket used for communicating with the client.
        /// </summary>
        [Input("sendTimeout")]
        public Input<int>? SendTimeout { get; set; }

        /// <summary>
        /// Sets behaviour on overflow in the set resulting. Possible values:
        /// </summary>
        [Input("setOverflowMode")]
        public Input<string>? SetOverflowMode { get; set; }

        /// <summary>
        /// Enables or disables silently skipping of unavailable shards.
        /// </summary>
        [Input("skipUnavailableShards")]
        public Input<bool>? SkipUnavailableShards { get; set; }

        /// <summary>
        /// Sets behaviour on overflow while sort. Possible values:
        /// </summary>
        [Input("sortOverflowMode")]
        public Input<string>? SortOverflowMode { get; set; }

        /// <summary>
        /// Sets behaviour on overflow. Possible values:
        /// </summary>
        [Input("timeoutOverflowMode")]
        public Input<string>? TimeoutOverflowMode { get; set; }

        /// <summary>
        /// Sets behaviour on overflow. Possible values:
        /// </summary>
        [Input("transferOverflowMode")]
        public Input<string>? TransferOverflowMode { get; set; }

        /// <summary>
        /// Enables equality of NULL values for IN operator.
        /// </summary>
        [Input("transformNullIn")]
        public Input<bool>? TransformNullIn { get; set; }

        /// <summary>
        /// Whether to use a cache of uncompressed blocks.
        /// </summary>
        [Input("useUncompressedCache")]
        public Input<bool>? UseUncompressedCache { get; set; }

        public MdbClickhouseClusterUserSettingsGetArgs()
        {
        }
    }
}
