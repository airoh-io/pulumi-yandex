// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Yandex.Outputs
{

    [OutputType]
    public sealed class MdbClickhouseClusterClickhouseConfigMergeTree
    {
        /// <summary>
        /// Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
        /// </summary>
        public readonly int? MaxBytesToMergeAtMinSpaceInPool;
        /// <summary>
        /// Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
        /// </summary>
        public readonly int? MaxReplicatedMergesInQueue;
        /// <summary>
        /// Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
        /// </summary>
        public readonly int? NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge;
        /// <summary>
        /// Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
        /// </summary>
        public readonly int? PartsToDelayInsert;
        /// <summary>
        /// Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
        /// </summary>
        public readonly int? PartsToThrowInsert;
        /// <summary>
        /// Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
        /// </summary>
        public readonly int? ReplicatedDeduplicationWindow;
        /// <summary>
        /// Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
        /// </summary>
        public readonly int? ReplicatedDeduplicationWindowSeconds;

        [OutputConstructor]
        private MdbClickhouseClusterClickhouseConfigMergeTree(
            int? maxBytesToMergeAtMinSpaceInPool,

            int? maxReplicatedMergesInQueue,

            int? numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge,

            int? partsToDelayInsert,

            int? partsToThrowInsert,

            int? replicatedDeduplicationWindow,

            int? replicatedDeduplicationWindowSeconds)
        {
            MaxBytesToMergeAtMinSpaceInPool = maxBytesToMergeAtMinSpaceInPool;
            MaxReplicatedMergesInQueue = maxReplicatedMergesInQueue;
            NumberOfFreeEntriesInPoolToLowerMaxSizeOfMerge = numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge;
            PartsToDelayInsert = partsToDelayInsert;
            PartsToThrowInsert = partsToThrowInsert;
            ReplicatedDeduplicationWindow = replicatedDeduplicationWindow;
            ReplicatedDeduplicationWindowSeconds = replicatedDeduplicationWindowSeconds;
        }
    }
}
